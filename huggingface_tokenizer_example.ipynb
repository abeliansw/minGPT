{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "359697d5",
      "metadata": {
        "id": "359697d5"
      },
      "source": [
        "# LangChain Cookbook ðŸ‘¨â€ðŸ³ðŸ‘©â€ðŸ³"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dECOwWE7t_xm",
        "outputId": "be101c33-1064-478c-f949-396446f5416b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dECOwWE7t_xm",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.18.0\n",
        "!pip install transformers==4.28.0\n"
      ],
      "metadata": {
        "id": "9cOoHVFZdu_j",
        "outputId": "c725268f-290f-4c45-cda2-cde595639f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9cOoHVFZdu_j",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.18.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.18.0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.18.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.18.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.18.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate==0.18.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.18.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.18.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->accelerate==0.18.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate==0.18.0) (1.3.0)\n",
            "Requirement already satisfied: transformers==4.28.0 in /usr/local/lib/python3.10/dist-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Ax2xSJsTdvE5",
        "outputId": "64030b51-ed94-4c5e-bd4b-74dd1560f8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ax2xSJsTdvE5",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset('code_search_net','python')"
      ],
      "metadata": {
        "id": "RtOjsy21jf8i"
      },
      "id": "RtOjsy21jf8i",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnunst9LlJm_",
        "outputId": "f50a6147-8cfe-4331-b7a7-0115d2d70192"
      },
      "id": "cnunst9LlJm_",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
              "    num_rows: 412178\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train'].to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "dRCee7WhlJq9",
        "outputId": "c70ba513-6bd8-4540-f8c5-4f1f93cbfce1"
      },
      "id": "dRCee7WhlJq9",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              repository_name      func_path_in_repository  \\\n",
              "0             adamrehn/ue4cli            ue4cli/Utility.py   \n",
              "1             adamrehn/ue4cli            ue4cli/Utility.py   \n",
              "2             adamrehn/ue4cli            ue4cli/Utility.py   \n",
              "3             adamrehn/ue4cli            ue4cli/Utility.py   \n",
              "4             adamrehn/ue4cli  ue4cli/UnrealManagerBase.py   \n",
              "...                       ...                          ...   \n",
              "412173  lobocv/anonymoususage      anonymoususage/tools.py   \n",
              "412174  lobocv/anonymoususage      anonymoususage/tools.py   \n",
              "412175  lobocv/anonymoususage      anonymoususage/tools.py   \n",
              "412176  lobocv/anonymoususage      anonymoususage/tools.py   \n",
              "412177  lobocv/anonymoususage      anonymoususage/tools.py   \n",
              "\n",
              "                                      func_name  \\\n",
              "0                              Utility.findArgs   \n",
              "1                             Utility.stripArgs   \n",
              "2                               Utility.capture   \n",
              "3                                   Utility.run   \n",
              "4       UnrealManagerBase.setEngineRootOverride   \n",
              "...                                         ...   \n",
              "412173                                 get_rows   \n",
              "412174                                    fetch   \n",
              "412175                             get_last_row   \n",
              "412176                            get_first_row   \n",
              "412177                          merge_databases   \n",
              "\n",
              "                                        whole_func_string language  \\\n",
              "0       def findArgs(args, prefixes):\\n\\t\\t\"\"\"\\n\\t\\tEx...   python   \n",
              "1       def stripArgs(args, blacklist):\\n\\t\\t\"\"\"\\n\\t\\t...   python   \n",
              "2       def capture(command, input=None, cwd=None, she...   python   \n",
              "3       def run(command, cwd=None, shell=False, raiseO...   python   \n",
              "4       def setEngineRootOverride(self, rootDir):\\n\\t\\...   python   \n",
              "...                                                   ...      ...   \n",
              "412173  def get_rows(dbconn, tablename, uuid=None):\\n ...   python   \n",
              "412174  def fetch(dbconn, tablename, n=1, uuid=None, e...   python   \n",
              "412175  def get_last_row(dbconn, tablename, n=1, uuid=...   python   \n",
              "412176  def get_first_row(dbconn, tablename, n=1, uuid...   python   \n",
              "412177  def merge_databases(master, part):\\n    \"\"\"\\n ...   python   \n",
              "\n",
              "                                         func_code_string  \\\n",
              "0       def findArgs(args, prefixes):\\n\\t\\t\"\"\"\\n\\t\\tEx...   \n",
              "1       def stripArgs(args, blacklist):\\n\\t\\t\"\"\"\\n\\t\\t...   \n",
              "2       def capture(command, input=None, cwd=None, she...   \n",
              "3       def run(command, cwd=None, shell=False, raiseO...   \n",
              "4       def setEngineRootOverride(self, rootDir):\\n\\t\\...   \n",
              "...                                                   ...   \n",
              "412173  def get_rows(dbconn, tablename, uuid=None):\\n ...   \n",
              "412174  def fetch(dbconn, tablename, n=1, uuid=None, e...   \n",
              "412175  def get_last_row(dbconn, tablename, n=1, uuid=...   \n",
              "412176  def get_first_row(dbconn, tablename, n=1, uuid...   \n",
              "412177  def merge_databases(master, part):\\n    \"\"\"\\n ...   \n",
              "\n",
              "                                         func_code_tokens  \\\n",
              "0       [def, findArgs, (, args, ,, prefixes, ), :, re...   \n",
              "1       [def, stripArgs, (, args, ,, blacklist, ), :, ...   \n",
              "2       [def, capture, (, command, ,, input, =, None, ...   \n",
              "3       [def, run, (, command, ,, cwd, =, None, ,, she...   \n",
              "4       [def, setEngineRootOverride, (, self, ,, rootD...   \n",
              "...                                                   ...   \n",
              "412173  [def, get_rows, (, dbconn, ,, tablename, ,, uu...   \n",
              "412174  [def, fetch, (, dbconn, ,, tablename, ,, n, =,...   \n",
              "412175  [def, get_last_row, (, dbconn, ,, tablename, ,...   \n",
              "412176  [def, get_first_row, (, dbconn, ,, tablename, ...   \n",
              "412177  [def, merge_databases, (, master, ,, part, ), ...   \n",
              "\n",
              "                                func_documentation_string  \\\n",
              "0       Extracts the list of arguments that start with...   \n",
              "1       Removes any arguments in the supplied list tha...   \n",
              "2        Executes a child process and captures its output   \n",
              "3       Executes a child process and waits for it to c...   \n",
              "4       Sets a user-specified directory as the root en...   \n",
              "...                                                   ...   \n",
              "412173  Return all the rows in a table from dbconn\\n  ...   \n",
              "412174  Returns `n` rows from the table's start or end...   \n",
              "412175             Returns the last `n` rows in the table   \n",
              "412176            Returns the first `n` rows in the table   \n",
              "412177  Merge the partial database into the master dat...   \n",
              "\n",
              "                                func_documentation_tokens split_name  \\\n",
              "0       [Extracts, the, list, of, arguments, that, sta...      train   \n",
              "1       [Removes, any, arguments, in, the, supplied, l...      train   \n",
              "2       [Executes, a, child, process, and, captures, i...      train   \n",
              "3       [Executes, a, child, process, and, waits, for,...      train   \n",
              "4       [Sets, a, user, -, specified, directory, as, t...      train   \n",
              "...                                                   ...        ...   \n",
              "412173  [Return, all, the, rows, in, a, table, from, d...      train   \n",
              "412174  [Returns, n, rows, from, the, table, s, start,...      train   \n",
              "412175      [Returns, the, last, n, rows, in, the, table]      train   \n",
              "412176     [Returns, the, first, n, rows, in, the, table]      train   \n",
              "412177  [Merge, the, partial, database, into, the, mas...      train   \n",
              "\n",
              "                                            func_code_url  \n",
              "0       https://github.com/adamrehn/ue4cli/blob/f1c345...  \n",
              "1       https://github.com/adamrehn/ue4cli/blob/f1c345...  \n",
              "2       https://github.com/adamrehn/ue4cli/blob/f1c345...  \n",
              "3       https://github.com/adamrehn/ue4cli/blob/f1c345...  \n",
              "4       https://github.com/adamrehn/ue4cli/blob/f1c345...  \n",
              "...                                                   ...  \n",
              "412173  https://github.com/lobocv/anonymoususage/blob/...  \n",
              "412174  https://github.com/lobocv/anonymoususage/blob/...  \n",
              "412175  https://github.com/lobocv/anonymoususage/blob/...  \n",
              "412176  https://github.com/lobocv/anonymoususage/blob/...  \n",
              "412177  https://github.com/lobocv/anonymoususage/blob/...  \n",
              "\n",
              "[412178 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad54b9dd-65ba-4261-91b0-a26c63d88c2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repository_name</th>\n",
              "      <th>func_path_in_repository</th>\n",
              "      <th>func_name</th>\n",
              "      <th>whole_func_string</th>\n",
              "      <th>language</th>\n",
              "      <th>func_code_string</th>\n",
              "      <th>func_code_tokens</th>\n",
              "      <th>func_documentation_string</th>\n",
              "      <th>func_documentation_tokens</th>\n",
              "      <th>split_name</th>\n",
              "      <th>func_code_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adamrehn/ue4cli</td>\n",
              "      <td>ue4cli/Utility.py</td>\n",
              "      <td>Utility.findArgs</td>\n",
              "      <td>def findArgs(args, prefixes):\\n\\t\\t\"\"\"\\n\\t\\tEx...</td>\n",
              "      <td>python</td>\n",
              "      <td>def findArgs(args, prefixes):\\n\\t\\t\"\"\"\\n\\t\\tEx...</td>\n",
              "      <td>[def, findArgs, (, args, ,, prefixes, ), :, re...</td>\n",
              "      <td>Extracts the list of arguments that start with...</td>\n",
              "      <td>[Extracts, the, list, of, arguments, that, sta...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/adamrehn/ue4cli/blob/f1c345...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adamrehn/ue4cli</td>\n",
              "      <td>ue4cli/Utility.py</td>\n",
              "      <td>Utility.stripArgs</td>\n",
              "      <td>def stripArgs(args, blacklist):\\n\\t\\t\"\"\"\\n\\t\\t...</td>\n",
              "      <td>python</td>\n",
              "      <td>def stripArgs(args, blacklist):\\n\\t\\t\"\"\"\\n\\t\\t...</td>\n",
              "      <td>[def, stripArgs, (, args, ,, blacklist, ), :, ...</td>\n",
              "      <td>Removes any arguments in the supplied list tha...</td>\n",
              "      <td>[Removes, any, arguments, in, the, supplied, l...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/adamrehn/ue4cli/blob/f1c345...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adamrehn/ue4cli</td>\n",
              "      <td>ue4cli/Utility.py</td>\n",
              "      <td>Utility.capture</td>\n",
              "      <td>def capture(command, input=None, cwd=None, she...</td>\n",
              "      <td>python</td>\n",
              "      <td>def capture(command, input=None, cwd=None, she...</td>\n",
              "      <td>[def, capture, (, command, ,, input, =, None, ...</td>\n",
              "      <td>Executes a child process and captures its output</td>\n",
              "      <td>[Executes, a, child, process, and, captures, i...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/adamrehn/ue4cli/blob/f1c345...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adamrehn/ue4cli</td>\n",
              "      <td>ue4cli/Utility.py</td>\n",
              "      <td>Utility.run</td>\n",
              "      <td>def run(command, cwd=None, shell=False, raiseO...</td>\n",
              "      <td>python</td>\n",
              "      <td>def run(command, cwd=None, shell=False, raiseO...</td>\n",
              "      <td>[def, run, (, command, ,, cwd, =, None, ,, she...</td>\n",
              "      <td>Executes a child process and waits for it to c...</td>\n",
              "      <td>[Executes, a, child, process, and, waits, for,...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/adamrehn/ue4cli/blob/f1c345...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adamrehn/ue4cli</td>\n",
              "      <td>ue4cli/UnrealManagerBase.py</td>\n",
              "      <td>UnrealManagerBase.setEngineRootOverride</td>\n",
              "      <td>def setEngineRootOverride(self, rootDir):\\n\\t\\...</td>\n",
              "      <td>python</td>\n",
              "      <td>def setEngineRootOverride(self, rootDir):\\n\\t\\...</td>\n",
              "      <td>[def, setEngineRootOverride, (, self, ,, rootD...</td>\n",
              "      <td>Sets a user-specified directory as the root en...</td>\n",
              "      <td>[Sets, a, user, -, specified, directory, as, t...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/adamrehn/ue4cli/blob/f1c345...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412173</th>\n",
              "      <td>lobocv/anonymoususage</td>\n",
              "      <td>anonymoususage/tools.py</td>\n",
              "      <td>get_rows</td>\n",
              "      <td>def get_rows(dbconn, tablename, uuid=None):\\n ...</td>\n",
              "      <td>python</td>\n",
              "      <td>def get_rows(dbconn, tablename, uuid=None):\\n ...</td>\n",
              "      <td>[def, get_rows, (, dbconn, ,, tablename, ,, uu...</td>\n",
              "      <td>Return all the rows in a table from dbconn\\n  ...</td>\n",
              "      <td>[Return, all, the, rows, in, a, table, from, d...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/lobocv/anonymoususage/blob/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412174</th>\n",
              "      <td>lobocv/anonymoususage</td>\n",
              "      <td>anonymoususage/tools.py</td>\n",
              "      <td>fetch</td>\n",
              "      <td>def fetch(dbconn, tablename, n=1, uuid=None, e...</td>\n",
              "      <td>python</td>\n",
              "      <td>def fetch(dbconn, tablename, n=1, uuid=None, e...</td>\n",
              "      <td>[def, fetch, (, dbconn, ,, tablename, ,, n, =,...</td>\n",
              "      <td>Returns `n` rows from the table's start or end...</td>\n",
              "      <td>[Returns, n, rows, from, the, table, s, start,...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/lobocv/anonymoususage/blob/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412175</th>\n",
              "      <td>lobocv/anonymoususage</td>\n",
              "      <td>anonymoususage/tools.py</td>\n",
              "      <td>get_last_row</td>\n",
              "      <td>def get_last_row(dbconn, tablename, n=1, uuid=...</td>\n",
              "      <td>python</td>\n",
              "      <td>def get_last_row(dbconn, tablename, n=1, uuid=...</td>\n",
              "      <td>[def, get_last_row, (, dbconn, ,, tablename, ,...</td>\n",
              "      <td>Returns the last `n` rows in the table</td>\n",
              "      <td>[Returns, the, last, n, rows, in, the, table]</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/lobocv/anonymoususage/blob/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412176</th>\n",
              "      <td>lobocv/anonymoususage</td>\n",
              "      <td>anonymoususage/tools.py</td>\n",
              "      <td>get_first_row</td>\n",
              "      <td>def get_first_row(dbconn, tablename, n=1, uuid...</td>\n",
              "      <td>python</td>\n",
              "      <td>def get_first_row(dbconn, tablename, n=1, uuid...</td>\n",
              "      <td>[def, get_first_row, (, dbconn, ,, tablename, ...</td>\n",
              "      <td>Returns the first `n` rows in the table</td>\n",
              "      <td>[Returns, the, first, n, rows, in, the, table]</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/lobocv/anonymoususage/blob/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412177</th>\n",
              "      <td>lobocv/anonymoususage</td>\n",
              "      <td>anonymoususage/tools.py</td>\n",
              "      <td>merge_databases</td>\n",
              "      <td>def merge_databases(master, part):\\n    \"\"\"\\n ...</td>\n",
              "      <td>python</td>\n",
              "      <td>def merge_databases(master, part):\\n    \"\"\"\\n ...</td>\n",
              "      <td>[def, merge_databases, (, master, ,, part, ), ...</td>\n",
              "      <td>Merge the partial database into the master dat...</td>\n",
              "      <td>[Merge, the, partial, database, into, the, mas...</td>\n",
              "      <td>train</td>\n",
              "      <td>https://github.com/lobocv/anonymoususage/blob/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>412178 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad54b9dd-65ba-4261-91b0-a26c63d88c2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad54b9dd-65ba-4261-91b0-a26c63d88c2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad54b9dd-65ba-4261-91b0-a26c63d88c2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c226af5-f8f8-423b-8da9-416ed4040dbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c226af5-f8f8-423b-8da9-416ed4040dbd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c226af5-f8f8-423b-8da9-416ed4040dbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb3nQC_YlJvD",
        "outputId": "8c23ec61-26c4-4d61-e601-7c6087d944b4"
      },
      "id": "Lb3nQC_YlJvD",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def build_cert_chain(self, flags=SSL_BUILD_CHAIN_FLAG_NONE):\n",
            "        u'''\n",
            "        Used for server side only!\n",
            "\n",
            "        :param flags:\n",
            "        :return: 1 for success and 0 for failure\n",
            "        '''\n",
            "        retVal = SSL_CTX_build_cert_chain(self._ctx, flags)\n",
            "        return retVal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_corpus = (\n",
        "    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
        "    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
        ")"
      ],
      "metadata": {
        "id": "5gzb1UNjlJx5"
      },
      "id": "5gzb1UNjlJx5",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = (i for i in range(10))\n",
        "print(list(gen))\n",
        "print(list(gen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-eUhpSglJ1N",
        "outputId": "b03c90e4-f2cb-460e-ed83-d21f7df709fb"
      },
      "id": "J-eUhpSglJ1N",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus():\n",
        "    return (\n",
        "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
        "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
        "    )\n",
        "\n",
        "training_corpus = get_training_corpus()"
      ],
      "metadata": {
        "id": "11lVCq4Tmu5H"
      },
      "id": "11lVCq4Tmu5H",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "sxVFrWeYmu8k"
      },
      "id": "sxVFrWeYmu8k",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = '''def add_numbers(a, b):\n",
        "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
        "    return a + b'''\n",
        "\n",
        "tokens = old_tokenizer.tokenize(example)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-f81Lk1mu_k",
        "outputId": "ae3cf6f5-4215-4739-b04e-54da1184a2e8"
      },
      "id": "T-f81Lk1mu_k",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['def',\n",
              " 'Ä add',\n",
              " '_',\n",
              " 'n',\n",
              " 'umbers',\n",
              " '(',\n",
              " 'a',\n",
              " ',',\n",
              " 'Ä b',\n",
              " '):',\n",
              " 'ÄŠ',\n",
              " 'Ä ',\n",
              " 'Ä ',\n",
              " 'Ä ',\n",
              " 'Ä \"\"\"',\n",
              " 'Add',\n",
              " 'Ä the',\n",
              " 'Ä two',\n",
              " 'Ä numbers',\n",
              " 'Ä `',\n",
              " 'a',\n",
              " '`',\n",
              " 'Ä and',\n",
              " 'Ä `',\n",
              " 'b',\n",
              " '`',\n",
              " '.\"',\n",
              " '\"\"',\n",
              " 'ÄŠ',\n",
              " 'Ä ',\n",
              " 'Ä ',\n",
              " 'Ä ',\n",
              " 'Ä return',\n",
              " 'Ä a',\n",
              " 'Ä +',\n",
              " 'Ä b']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
      ],
      "metadata": {
        "id": "yQqyZSdnmvDY"
      },
      "id": "yQqyZSdnmvDY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize(example)\n",
        "tokens"
      ],
      "metadata": {
        "id": "cXzA_ZoumvGn"
      },
      "id": "cXzA_ZoumvGn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokens))\n",
        "print(len(old_tokenizer.tokenize(example)))"
      ],
      "metadata": {
        "id": "DCB8AgcgmvJ9"
      },
      "id": "DCB8AgcgmvJ9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"\"\"class LinearLayer():\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weight = torch.randn(input_size, output_size)\n",
        "        self.bias = torch.zeros(output_size)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x @ self.weights + self.bias\n",
        "    \"\"\"\n",
        "tokenizer.tokenize(example)"
      ],
      "metadata": {
        "id": "gupZWdchqLmu"
      },
      "id": "gupZWdchqLmu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"code-search-net-tokenizer\")"
      ],
      "metadata": {
        "id": "cUb4hYL6qLqA"
      },
      "id": "cUb4hYL6qLqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/test/backup/code-search-net-tokenizer\")"
      ],
      "metadata": {
        "id": "C5kwT5DtqLs8"
      },
      "id": "C5kwT5DtqLs8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
        "encoding = tokenizer(example)\n",
        "print(type(encoding))"
      ],
      "metadata": {
        "id": "Gu40GgCWqLwU"
      },
      "id": "Gu40GgCWqLwU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding"
      ],
      "metadata": {
        "id": "rOxHkeYSqLzp"
      },
      "id": "rOxHkeYSqLzp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65Qf66JGmvNn"
      },
      "id": "65Qf66JGmvNn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "id": "xZIp1GVYlJ4P"
      },
      "id": "xZIp1GVYlJ4P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.is_fast"
      ],
      "metadata": {
        "id": "txCq6tkZmvi8"
      },
      "id": "txCq6tkZmvi8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.tokens()"
      ],
      "metadata": {
        "id": "Eh3lag0rmvmQ"
      },
      "id": "Eh3lag0rmvmQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.word_ids()"
      ],
      "metadata": {
        "id": "O71KsdAshS5C"
      },
      "id": "O71KsdAshS5C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start, end = encoding.word_to_chars(3)\n",
        "example[start:end]"
      ],
      "metadata": {
        "id": "06BdIeBEhS8B"
      },
      "id": "06BdIeBEhS8B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "token_classifier = pipeline(\"token-classification\")\n",
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "wy8cKX2qhS-q"
      },
      "id": "wy8cKX2qhS-q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")\n",
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "WNa0rVTahTB7"
      },
      "id": "WNa0rVTahTB7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
        "inputs = tokenizer(example, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "-jkjqtd-hTEs"
      },
      "id": "-jkjqtd-hTEs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs\n"
      ],
      "metadata": {
        "id": "289yJBH8hTHe"
      },
      "id": "289yJBH8hTHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[\"input_ids\"].shape)\n",
        "print(outputs.logits.shape)"
      ],
      "metadata": {
        "id": "8_iaHDCGhTKm"
      },
      "id": "8_iaHDCGhTKm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\n",
        "predictions = outputs.logits.argmax(dim=-1)[0].tolist()\n",
        "print(probabilities)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "8P4IwxOshTNQ"
      },
      "id": "8P4IwxOshTNQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label"
      ],
      "metadata": {
        "id": "yClUjkWZpDY6"
      },
      "id": "yClUjkWZpDY6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "tokens = inputs.tokens()\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\":\n",
        "        results.append(\n",
        "            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n",
        "        )\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "mYnRW2HNpDeP"
      },
      "id": "mYnRW2HNpDeP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
        "inputs_with_offsets[\"offset_mapping\"]"
      ],
      "metadata": {
        "id": "mrOqZk_YpDiR"
      },
      "id": "mrOqZk_YpDiR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example[12:14]"
      ],
      "metadata": {
        "id": "LyhfZAjCpDlp"
      },
      "id": "LyhfZAjCpDlp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
        "tokens = inputs_with_offsets.tokens()\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != 'O':\n",
        "        start, end = offsets[idx]\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity\": label,\n",
        "                \"score\": probabilities[idx][pred],\n",
        "                \"word\": tokens[idx],\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "            }\n",
        "        )\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "c3v87RjopDpa"
      },
      "id": "c3v87RjopDpa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example[33:45]"
      ],
      "metadata": {
        "id": "kr0hFXy0pDtY"
      },
      "id": "kr0hFXy0pDtY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "results = []\n",
        "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
        "tokens = inputs_with_offsets.tokens()\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "idx = 0\n",
        "while idx < len(predictions):\n",
        "    pred = predictions[idx]\n",
        "    label = model.config.id2label[pred]\n",
        "    if label != \"O\":\n",
        "        # Remove the B- or I-\n",
        "        label = label[2:]\n",
        "        start, _ = offsets[idx]\n",
        "\n",
        "        # Grab all the tokens labeled with I-label\n",
        "        all_scores = []\n",
        "        while (\n",
        "            idx < len(predictions)\n",
        "            and model.config.id2label[predictions[idx]] == f\"I-{label}\"\n",
        "        ):\n",
        "            all_scores.append(probabilities[idx][pred])\n",
        "            _, end = offsets[idx]\n",
        "            idx += 1\n",
        "\n",
        "        # The score is the mean of all the scores of the tokens in that grouped entity\n",
        "        score = np.mean(all_scores).item()\n",
        "        word = example[start:end]\n",
        "        results.append(\n",
        "            {\n",
        "                \"entity_group\": label,\n",
        "                \"score\": score,\n",
        "                \"word\": word,\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "            }\n",
        "        )\n",
        "    idx += 1\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "0VHilP4npDxf"
      },
      "id": "0VHilP4npDxf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "context = \"\"\"\n",
        "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question = \"Which deep learning libraries back ðŸ¤— Transformers?\"\n",
        "question_answerer(question=question, context=context)"
      ],
      "metadata": {
        "id": "maXjorr8pD1W"
      },
      "id": "maXjorr8pD1W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "long_context = \"\"\"\n",
        "ðŸ¤— Transformers: State of the Art NLP\n",
        "\n",
        "ðŸ¤— Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
        "question answering, summarization, translation, text generation and more in over 100 languages.\n",
        "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
        "\n",
        "ðŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
        "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
        "can be modified to enable quick research experiments.\n",
        "\n",
        "Why should I use transformers?\n",
        "\n",
        "1. Easy-to-use state-of-the-art models:\n",
        "  - High performance on NLU and NLG tasks.\n",
        "  - Low barrier to entry for educators and practitioners.\n",
        "  - Few user-facing abstractions with just three classes to learn.\n",
        "  - A unified API for using all our pretrained models.\n",
        "  - Lower compute costs, smaller carbon footprint:\n",
        "\n",
        "2. Researchers can share trained models instead of always retraining.\n",
        "  - Practitioners can reduce compute time and production costs.\n",
        "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
        "\n",
        "3. Choose the right framework for every part of a model's lifetime:\n",
        "  - Train state-of-the-art models in 3 lines of code.\n",
        "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
        "  - Seamlessly pick the right framework for training, evaluation and production.\n",
        "\n",
        "4. Easily customize a model or an example to your needs:\n",
        "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
        "  - Model internals are exposed as consistently as possible.\n",
        "  - Model files can be used independently of the library for quick experiments.\n",
        "\n",
        "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration\n",
        "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
        "\"\"\"\n",
        "question_answerer(question=question, context=long_context)"
      ],
      "metadata": {
        "id": "U9s_IeGFpD4p"
      },
      "id": "U9s_IeGFpD4p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "vigxkXFTq9d0"
      },
      "id": "vigxkXFTq9d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "print(start_logits.shape, end_logits.shape)"
      ],
      "metadata": {
        "id": "LNJsgPJvq9hB"
      },
      "id": "LNJsgPJvq9hB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sequence_ids = inputs.sequence_ids()\n",
        "# ì»¨í…ìŠ¤íŠ¸ í† í°ë“¤ì„ ì œì™¸í•˜ê³ ëŠ” ëª¨ë‘ ë§ˆìŠ¤í‚¹í•œë‹¤.\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "# [CLS] í† í°ì€ ë§ˆìŠ¤í‚¹í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
        "mask[0] = False\n",
        "mask = torch.tensor(mask)[None]\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ],
      "metadata": {
        "id": "aGYyaCtXq9kT"
      },
      "id": "aGYyaCtXq9kT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]"
      ],
      "metadata": {
        "id": "6RoiWbPLq9nS"
      },
      "id": "6RoiWbPLq9nS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = start_probabilities[:, None] * end_probabilities[None, :]"
      ],
      "metadata": {
        "id": "hHrvt7pyq9qZ"
      },
      "id": "hHrvt7pyq9qZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = torch.triu(scores)"
      ],
      "metadata": {
        "id": "FPoqNi18q9ti"
      },
      "id": "FPoqNi18q9ti",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_index = scores.argmax().item()\n",
        "start_index = max_index // scores.shape[1]\n",
        "end_index = max_index % scores.shape[1]\n",
        "print(scores[start_index, end_index])"
      ],
      "metadata": {
        "id": "7q8GfPI_q9wx"
      },
      "id": "7q8GfPI_q9wx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)\n",
        "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
        "\n",
        "start_char, _ = offsets[start_index]\n",
        "_, end_char = offsets[end_index]\n",
        "answer = context[start_char:end_char]"
      ],
      "metadata": {
        "id": "FGDWvpZXq9z-"
      },
      "id": "FGDWvpZXq9z-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = {\n",
        "    \"answer\": answer,\n",
        "    \"start\": start_char,\n",
        "    \"end\": end_char,\n",
        "    \"score\": scores[start_index, end_index]\n",
        "}\n",
        "print(result)"
      ],
      "metadata": {
        "id": "vqzodiyxuYGX"
      },
      "id": "vqzodiyxuYGX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(question, long_context)\n",
        "print(len(inputs[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "DRq7y8IMuYJi"
      },
      "id": "DRq7y8IMuYJi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(question, long_context, max_length=384, truncation=\"only_second\")\n",
        "print(tokenizer.decode(inputs[\"input_ids\"]))"
      ],
      "metadata": {
        "id": "EhadEvH8uYMy"
      },
      "id": "EhadEvH8uYMy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"This sentence is not too long but we are going to split it anyway.\"\n",
        "inputs = tokenizer(\n",
        "    sentence, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "for ids in inputs[\"input_ids\"]:\n",
        "    print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "id": "xp_1Q8hBuYQe"
      },
      "id": "xp_1Q8hBuYQe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.keys())"
      ],
      "metadata": {
        "id": "fnDob4QMuYT5"
      },
      "id": "fnDob4QMuYT5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ],
      "metadata": {
        "id": "wAkSVnz0uYXW"
      },
      "id": "wAkSVnz0uYXW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"This sentence is not too long but we are going to split it anyway.\",\n",
        "    \"This sentence is shorter but will still get split.\",\n",
        "]\n",
        "inputs = tokenizer(\n",
        "    sentences, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
        ")\n",
        "\n",
        "print(inputs[\"overflow_to_sample_mapping\"])"
      ],
      "metadata": {
        "id": "G1PwpuweuYaZ"
      },
      "id": "G1PwpuweuYaZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    question,\n",
        "    long_context,\n",
        "    stride=128,\n",
        "    max_length=384,\n",
        "    padding=\"longest\",\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        ")"
      ],
      "metadata": {
        "id": "5B3WnRT1u8AF"
      },
      "id": "5B3WnRT1u8AF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "offsets = inputs.pop(\"offset_mapping\")\n",
        "\n",
        "inputs = inputs.convert_to_tensors(\"pt\")\n",
        "print(inputs[\"input_ids\"].shape)"
      ],
      "metadata": {
        "id": "vYcAngDIu8Dq"
      },
      "id": "vYcAngDIu8Dq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "print(start_logits.shape, end_logits.shape)"
      ],
      "metadata": {
        "id": "bIR_ZW0ou8GU"
      },
      "id": "bIR_ZW0ou8GU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_ids = inputs.sequence_ids()\n",
        "# Mask everything apart from the tokens of the context\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "# Unmask the [CLS] token\n",
        "mask[0] = False\n",
        "# Mask all the [PAD] tokens\n",
        "mask = torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] == 0))\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ],
      "metadata": {
        "id": "JFmCrkX4u8JB"
      },
      "id": "JFmCrkX4u8JB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n",
        "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)"
      ],
      "metadata": {
        "id": "j2FURXHIu8MI"
      },
      "id": "j2FURXHIu8MI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = []\n",
        "for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n",
        "    scores = start_probs[:, None] * end_probs[None, :]\n",
        "    idx = torch.triu(scores).argmax().item()\n",
        "\n",
        "    start_idx = idx // scores.shape[0]\n",
        "    end_idx = idx % scores.shape[0]\n",
        "    score = scores[start_idx, end_idx].item()\n",
        "    candidates.append((start_idx, end_idx, score))\n",
        "\n",
        "print(candidates)"
      ],
      "metadata": {
        "id": "vEQKvhn_u8PS"
      },
      "id": "vEQKvhn_u8PS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for candidate, offset in zip(candidates, offsets):\n",
        "    start_token, end_token, score = candidate\n",
        "    start_char, _ = offset[start_token]\n",
        "    _, end_char = offset[end_token]\n",
        "    answer = long_context[start_char:end_char]\n",
        "    result = {\"answer\": answer, \"start\":start_char, \"end\":end_char, \"score\":score}\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "uW3LeiZAu8R-"
      },
      "id": "uW3LeiZAu8R-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VSWHMQvcu8VU"
      },
      "id": "VSWHMQvcu8VU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yGuYBq6qu8YR"
      },
      "id": "yGuYBq6qu8YR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSOezq9wu8a2"
      },
      "id": "ZSOezq9wu8a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMMcG1Kou8eE"
      },
      "id": "qMMcG1Kou8eE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}